<!doctype html>
<html lang="en" class="no-js">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Anna Hedstr√∂m</title>
  <meta name="description" content="Postdoctoral Fellow at the ETH AI Center. Research in interpretability, LLM alignment, and AI safety. Advising startups on applied AI." />
  <link rel="stylesheet" href="/assets/style.css" />
  <link rel="icon" href="/assets/favicon.png" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">

</head>
<body class="custom-background">
  <header class="site-header">
    <div class="container">
      <h1 class="site-title"><a href="/">Anna Hedstr√∂m</a></h1>
      <nav class="social" aria-label="Social links">
        <a href="mailto:hedstroem.anna@gmail.com" aria-label="Email"><i class="fa-solid fa-envelope"></i></a>
        <a href="https://scholar.google.com/citations?user=ldOYtBUAAAAJ&hl=en" aria-label="Google Scholar"><i class="fa-brands fa-google-scholar"></i></a>
        <a href="https://github.com/annahedstroem/" aria-label="GitHub"><i class="fa-brands fa-github"></i></a>
        <a href="https://de.linkedin.com/in/annahedstrom1" aria-label="LinkedIn"><i class="fa-brands fa-linkedin"></i></a>
        <a href="https://x.com/anna_hedstroem" aria-label="Twitter / X"><i class="fa-brands fa-x-twitter"></i></a>
      </nav>
    </div>
  </header>

  <main>
    <div class="container">
      <div class="columns">
        <div class="column-left">
          <img class="profile" src="/profile.png" alt="Portrait of Anna Hedstr√∂m" />
        </div>
        <div class="column-right">
          <p>Hi! I‚Äôm a Postdoctoral Fellow at the <a href="https://ai.ethz.ch/" target="_blank" rel="noopener">ETH AI Center</a>, supervised by <a href="https://el-assady.com/" target="_blank" rel="noopener">Prof. Dr. Menna El‚ÄëAssady</a> and <a href="https://las.inf.ethz.ch/krausea" target="_blank" rel="noopener">Prof. Dr. Andreas Krause</a>. My research focuses on evaluation-centric interpretability, large language model (LLM) alignment and safety.</p>
          <p>I completed a Ph.D. in Machine Learning at <a href="https://www.tu.berlin/en/" target="_blank" rel="noopener">TU Berlin</a> with distinction, advised by <a href="https://www.atb-potsdam.de/de/ueber-uns/team/mitarbeiter/person/marina-hohne" target="_blank" rel="noopener">Prof. Dr. Marina H√∂hne</a> and <a href="https://iphome.hhi.de/samek/" target="_blank" rel="noopener">Prof. Dr. Wojciech Samek</a>. I hold an M.Sc. from <a href="https://www.kth.se/en" target="_blank" rel="noopener">KTH</a> and a B.Sc. from <a href="https://www.ucl.ac.uk/" target="_blank" rel="noopener">UCL</a>.</p>
          <p>Previously, I held multiple ML roles across industry; most recently, I joined the AI Research Programme at <a href="https://www.jpmorgan.com/CH/en/about-us" target="_blank" rel="noopener">J.P. Morgan</a> working on mechanistic steering of LLMs. Before my Ph.D., I freelanced, worked with credit risk at <a href="https://www.klarna.com/" target="_blank" rel="noopener">Klarna</a>, time‚Äëseries modeling at <a href="https://www.bosch.com/" target="_blank" rel="noopener">Bosch</a>, and interned at <a href="https://blackswan.com/" target="_blank" rel="noopener">Black Swan Data</a> and <a href="https://www.bcg.com/" target="_blank" rel="noopener">BCG</a>. I like to contribute to open‚Äësource software (e.g., <a href="https://github.com/understandable-machine-intelligence-lab/Quantus" target="_blank" rel="noopener">Quantus</a>) and advise startups on AI.</p>

          <p>üìç I'm currently based in Z√ºrich, Switzerland.</p>
          <p>‚úâÔ∏è Email: <a href="mailto:hedstroem.anna@gmail.com">hedstroem.anna@gmail.com</a></p>
          
        </div>
      </div>

      <h2>Selected Research</h2>
      <p class="small">Full list: <a href="https://scholar.google.com/citations?user=ldOYtBUAAAAJ&hl=en" target="_blank" rel="noopener">Google Scholar</a></p>
      <div class="pub-item">
        <div class="pub-title">To Steer or Not to Steer? Mechanistic Error Reduction with Abstention for Language Models</div>
        <div class="pub-authors"><u>Hedstr√∂m A.</u>, Amoukou S. I., Bewley T., Mishra S., Veloso M.</div>
        <div class="pub-meta"><em>ICML</em>, 2025.</div><div class="btn-group">
          <a class="btn" href="https://openreview.net/pdf?id=fUCPq5RvmH" target="_blank" rel="noopener">Paper</a>
          <a class="btn" href="https://github.com/annahedstroem/MERA-steering" target="_blank" rel="noopener">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{anna2025abstention,
  title = {To Steer or Not to Steer? Mechanistic Error Reduction with Abstention for Language Models},
  author = {\textbf{Hedstr{\"o}m}, Anna and Amoukou, Salim and Bewley, Tom and Mishra, Saumitra and Veloso, Manuela},
  booktitle={Forty-Second International Conference on Machine Learning (ICML)!},
  year={2025},
}</pre></details>
        </div>
      </div>

      <div class="pub-item">
        <div class="pub-title"><span class="badge-teal">(Survey certification!)</span> Evaluating Interpretable Methods via Geometric Alignment of Functional Distortions</div>
        <div class="pub-authors"><u>Hedstr√∂m A.</u>, Bommer P. L., Burns T. F., Lapuschkin S., Samek W., H√∂hne M.</div>
        <div class="pub-meta"><em>TMLR</em>, 2025.</div><div class="btn-group">
          <a class="btn" href="https://openreview.net/pdf?id=ukLxqA8zXj&noteId=5ceyt8qT4e" target="_blank" rel="noopener">Paper</a>
          <a class="btn" href="https://github.com/annahedstroem/GEF" target="_blank" rel="noopener">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{
gef2024,
title={\href{https://openreview.net/forum?id=ukLxqA8zXj&noteId=5ceyt8qT4e}{Evaluating Interpretable Methods via Geometric Alignment of Functional Distortions}},
author={\href{https://openreview.net/forum?id=ukLxqA8zXj&noteId=5ceyt8qT4e}{\textbf{(Survey Certification!)}} \textbf{Hedstr{\"o}m}, Anna and Bommer, Philine Lou and Tom, Burns and Lapuschkin, Sebastian and Samek, Wojciech  and H{\"o}hne, Marina M-C},
booktitle={Transactions on Machine Learning Research},
year={2025},
}</pre></details>
        </div>
      </div>
      
      <div class="pub-item">
        <div class="pub-title">The Price of Freedom: An Adversarial Attack on Interpretability Evaluation</div>
        <div class="pub-authors">Wickstr√∂m K. K., H√∂hne M., <u>Hedstr√∂m A.</u></div>
        <div class="pub-meta"><em>NeurIPS Workshop Interpretable AI</em>, 2024.</div><div class="btn-group">
          <a class="btn" href="https://openreview.net/pdf?id=BpJK5lFzfM" target="_blank" rel="noopener">Paper</a>
          <a class="btn" href="https://github.com/Wickstrom/quantitative-xai-manipulation" target="_blank" rel="noopener">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{
price2024neurips,
title={\href{https://openreview.net/pdf?id=BpJK5lFzfM}{The Price of Freedom: An Adversarial Attack on Interpretability Evaluation}},
author={Wickstr{\"o}m, Kristoffer Knutsen and H{\"o}hne, Marina MC and \textbf{Hedstr{\"o}m}, Anna},
booktitle={NeurIPS Workshop Interpretable AI: Past, Present and Future},
year={2024},
}</pre></details>
        </div>
      </div>

      <div class="pub-item">
        <div class="pub-title">CoSy: Evaluating Textual Explanations of Neurons</div>
        <div class="pub-authors">Kopf L., Bommer P. L., <u>Hedstr√∂m A.</u>, Lapuschkin S., H√∂hne M.</div>
        <div class="pub-meta"><em>NeurIPS</em>, 2024.</div><div class="btn-group">
          <a class="btn" href="https://openreview.net/pdf?id=R0bnWrpIeN" target="_blank" rel="noopener">Paper</a>
          <a class="btn" href="https://github.com/lkopf/cosy" target="_blank" rel="noopener">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{
kopf2024cosy,
title={\href{https://openreview.net/pdf?id=R0bnWrpIeN}{CoSy: Evaluating Textual Explanations of Neurons}},
author={Kopf, Laura and Bommer, Philine Lou and \textbf{Hedstr{\"o}m}, Anna and Lapuschkin, Sebastian, and H{\"o}hne, Marina M-C},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
}</pre></details>
        </div>
      </div>

      <!-- <div class="pub-item">
        <div class="pub-title">From Flexibility to Manipulation: The Slippery Slope of XAI Evaluation</div>
        <div class="pub-authors">K. K. Wickstr√∂m, M. H√∂hne, A. Hedstr√∂m</div>
        <div class="pub-meta"><em>ECCV Workshop</em>, 2024.</div>
        <div class="btn-group">
          <a class="btn" href="https://openreview.net/pdf?id=fd7g9nwI2R" target="_blank" rel="noopener">Paper</a>
          <a class="btn" href="#" aria-disabled="true">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{ flexibility2024eccv,
  title={From Flexibility to Manipulation: The Slippery Slope of XAI Evaluation},
  author={Wickstr{\"o}m, Kristoffer Knutsen and H{\"o}hne, Marina MC and Hedstr{\"o}m, Anna},
  booktitle={ECCV Workshop},
  year={2024}
}</pre></details>
        </div>
      </div> -->

      <!-- <div class="pub-item">
        <div class="pub-title">Finding the Right XAI Method‚ÄîA Guide for the Evaluation and Ranking of Explainable AI Methods in Climate Science</div>
        <div class="pub-authors">P. L. Bommer, M. Kretschmer, A. Hedstr√∂m, D. Bareeva, M. H√∂hne</div>
        <div class="pub-meta"><em>Artificial Intelligence for the Earth Systems</em>, 2024.</div>
        <div class="btn-group">
          <a class="btn" href="https://journals.ametsoc.org/downloadpdf/view/journals/aies/3/3/AIES-D-23-0074.1" target="_blank" rel="noopener">Paper</a>
          <a class="btn" href="#" aria-disabled="true">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{bommer2024finding,
  title={Finding the right XAI method‚Äîa guide for the evaluation and ranking of explainable AI methods in climate science},
  author={Bommer, Philine Lou and Kretschmer, Marlene and Hedstr{\"o}m, Anna and Bareeva, Dilyara and H{\"o}hne, Marina M-C},
  booktitle={Artificial Intelligence for the Earth Systems},
  volume={3},
  number={3},
  pages={e230074},
  year={2024},
  publisher={American Meteorological Society}
}</pre></details>
        </div>
      </div> -->

      <!-- <div class="pub-item">
        <div class="pub-title">CoSy: Evaluating Textual Explanations of Neurons</div>
        <div class="pub-authors">L. Kopf, P. L. Bommer, A. Hedstr√∂m, S. Lapuschkin, M. H√∂hne, K. Bykov</div>
        <div class="pub-meta"><em>ICML Workshop on Mechanistic Interpretability</em>, 2024.</div>
        <div class="btn-group">
          <a class="btn" href="https://openreview.net/pdf?id=2g84EvFlRt" target="_blank" rel="noopener">Paper</a>
          <a class="btn" href="#" aria-disabled="true">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{ kopf2024cosy2,
  title={CoSy: Evaluating Textual Explanations of Neurons},
  author={Laura Kopf and Philine Lou Bommer and Anna Hedstr{\"o}m and Sebastian Lapuschkin and Marina MC H{\"o}hne and Kirill Bykov},
  booktitle={ICML 2024 Workshop on Mechanistic Interpretability},
  year={2024}
}</pre></details>
        </div>
      </div> -->

      

      <div class="pub-item">
        <div class="pub-title">Quanda: An Interpretability Toolkit for Training Data Attribution Evaluation and Beyond</div>
        <div class="pub-authors">Bareeva D., Yolcu G. U., <u>Hedstr√∂m A.</u>, Schmolenski N., Wiegand T., Samek W., Lapuschkin S.</div>
        <div class="pub-meta"><em>NeurIPS Workshop on Attributing Model Behavior at Scale</em>, 2024.</div><div class="btn-group">
          <a class="btn" href="https://openreview.net/pdf?id=IFk4bOA11Z" target="_blank" rel="noopener">Paper</a>
          <a class="btn" href="https://github.com/dilyabareeva/quanda" target="_blank" rel="noopener">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{
quanda2024,
title={\href{https://openreview.net/pdf?id=IFk4bOA11Z}{Quanda: An Interpretability Toolkit for Training Data Attribution Evaluation and Beyond}},
  author={Bareeva, Dilyara and Yolcu, Galip Umit and \textbf{Hedstr√∂m}, Anna and Schmolenski, Niklas and Wiegand, Thomas and Samek, Wojciech and Lapuschkin, Sebastian},
booktitle={Second NeurIPS Workshop on Attributing Model Behavior at Scale},
year={2024},
}</pre></details>
        </div>
      </div>

      <!-- <div class="pub-item">
        <div class="pub-title">Sanity Checks Revisited: An Exploration to Repair the Model Parameter Randomisation Test</div>
        <div class="pub-authors">A. Hedstr√∂m, L. Weber, S. Lapuschkin, M. H√∂hne</div>
        <div class="pub-meta"><em>NeurIPS Workshop XAI in Action</em>, 2023.</div>
        <div class="btn-group">
          <a class="btn" href="https://openreview.net/pdf?id=vVpefYmnsG" target="_blank" rel="noopener">Paper</a>
          <a class="btn" href="https://github.com/annahedstroem/sanity-checks-revisited" target="_blank" rel="noopener">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{hedstromsanity,
  title={Sanity Checks Revisited: An Exploration to Repair the Model Parameter Randomisation Test},
  author={Hedstr{\"o}m, Anna and Weber, Leander and Lapuschkin, Sebastian and H{\"o}hne, Marina MC},
  booktitle={NeurIPS Workshop XAI in Action: Past, Present, and Future Applications},
  year={2023}
}</pre></details>
        </div>
      </div> -->

      <div class="pub-item">
        <div class="pub-title">Quantus: An Explainable AI Toolkit for Responsible Evaluation of Neural Network Explanations and Beyond</div>
        <div class="pub-authors"><u>Hedstr√∂m A.</u>, Weber L., Krakowczyk D., Bareeva D., Motzkus F., Samek W., Lapuschkin S., H√∂hne M.</div>
        <div class="pub-meta"><em>JMLR</em>, 2023.</div><div class="btn-group">
          <a class="btn" href="https://www.jmlr.org/papers/v24/22-0142.html" target="_blank" rel="noopener">Paper</a>
          <a class="btn" href="https://github.com/understandable-machine-intelligence-lab/Quantus" target="_blank" rel="noopener">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{hedstrom2023quantus,
  title={\href{https://www.jmlr.org/papers/v24/22-0142.html}{Quantus: An explainable ai toolkit for responsible evaluation of neural network explanations and beyond}},
  author={\textbf{Hedstr{\"o}m}, Anna and Weber, Leander and Krakowczyk, Daniel and Bareeva, Dilyara and Motzkus, Franz and Samek, Wojciech and Lapuschkin, Sebastian and H{\"o}hne, Marina M-C},
  booktitle={Journal of Machine Learning Research},
  volume={24},
  number={34},
  pages={1--11},
  year={2023},
}</pre></details>
        </div>
      </div>

      <div class="pub-item">
        <div class="pub-title">The Meta-Evaluation Problem in Explainable AI: Identifying Reliable Estimators with MetaQuantus</div>
        <div class="pub-authors"><u>Hedstr√∂m A.</u>, Bommer P. L., Wickstr√∂m K. K., Samek W., Lapuschkin S., H√∂hne M.</div>
        <div class="pub-meta"><em>TMLR</em>, 2023.</div><div class="btn-group">
          <a class="btn" href="https://openreview.net/pdf?id=j3FK00HyfU" target="_blank" rel="noopener">Paper</a>
          <a class="btn" href="https://github.com/annahedstroem/MetaQuantus" target="_blank" rel="noopener">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{hedstrommeta,
  title={\href{https://openreview.net/pdf?id=j3FK00HyfU}{The Meta-Evaluation Problem in Explainable AI: Identifying Reliable Estimators with MetaQuantus}},
  author={\textbf{Hedstr{\"o}m}, Anna and Bommer, Philine Lou and Wickstr{\"o}m, Kristoffer Knutsen and Samek, Wojciech and Lapuschkin, Sebastian and H{\"o}hne, Marina MC},
  booktitle={Transactions on Machine Learning Research},
  year={2023},
}</pre></details>
        </div>
      </div>

      <!-- <div class="pub-item">
        <div class="pub-title">Noisegrad‚ÄîEnhancing Explanations by Introducing Stochasticity to Model Weights</div>
        <div class="pub-authors">K. Bykov, A. Hedstr√∂m, S. Nakajima, M. M.-C. H√∂hne</div>
        <div class="pub-meta"><em>AAAI</em>, 2022.</div>
        <div class="btn-group">
          <a class="btn" href="https://ojs.aaai.org/index.php/AAAI/article/view/20561" target="_blank" rel="noopener">Paper</a>
          <a class="btn" href="https://github.com/understandable-machine-intelligence-lab/NoiseGrad" target="_blank" rel="noopener">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{bykov2022noisegrad,
  title={Noisegrad‚Äîenhancing explanations by introducing stochasticity to model weights},
  author={Bykov, Kirill and Hedstr{\"o}m, Anna and Nakajima, Shinichi and H{\"o}hne, Marina M-C},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36}, number={6}, pages={6132--6140},
  year={2022}
}</pre></details>
        </div>
      </div> -->

      <div class="pub-item">
        <div class="pub-title"><span class="badge-teal">(Spotlight!)</span> Tutorial: Quantus x Climate ‚Äî Applying Explainable AI Evaluation in Climate Science</div>
        <div class="pub-authors">Bommer P. L.*, <u>Hedstr√∂m A.</u>*, Kretschmer M., H√∂hne M. M.-C.</div>
        <div class="pub-meta"><em>ICLR Workshop on Climate Change AI</em>, 2023.</div><div class="btn-group">
          <a class="btn" href="https://www.climatechange.ai/papers/iclr2023/1" target="_blank" rel="noopener">Paper</a>
          <a class="btn" href="https://github.com/understandable-machine-intelligence-lab/Quantus" target="_blank" rel="noopener">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{bommer2023tutorial,
  title={\href{https://www.climatechange.ai/papers/iclr2023/1}{Tutorial: Quantus x Climate - Applying explainable AI evaluation in climate science}},
  author={\href{https://www.climatechange.ai/papers/iclr2023/1}{\textbf{(Spotlight!)}} Bommer, Philine L and \textbf{Hedstr{\"o}m}, Anna and Kretschmer, Marlene and H√∂hne, Marina M.-C.},
  booktitle={ICLR Workshop on Tackling Climate Change with Machine Learning},
  year={2023},
}</pre></details>
        </div>
      </div>


      <!-- <div class="pub-item">
        <div class="pub-title">Trustworthy AI in Medical Imaging: Methods, Evaluation and Clinical Considerations</div>
        <div class="pub-authors">T. Gon√ßalvesc, A. Hedstr√∂m, A. de Mortanges, X. Li, H. M√ºller, J. Cardoso, M. Reyes</div>
        <div class="pub-meta"><em>Book chapter, Springer</em>, 2025.</div>
        <div class="btn-group">
          <a class="btn" href="#" aria-disabled="true">Paper</a>
          <a class="btn" href="#" aria-disabled="true">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{bookspringer2025evaluate,
  title = {Trustworthy AI in Medical Imaging: Methods, Evaluation and Clinical Considerations},
  author = {Gon√ßalvesc, Tiago and Hedstr{\"o}m, Anna and de Mortanges, Aur√©lie and Li, Xiaoxiao and M√ºller, Henning and Cardoso, Jaime and Reyes, Mauricio},
  journal = {Book chapter, Springer, (978-0-443-23761-4)},
  year = {2025}
}</pre></details>
        </div>
      </div> -->

      <!-- <div class="pub-item">
        <div class="pub-title">Evaluate with the Inverse: Efficient Approximation of Latent Explanation Quality Distribution</div>
        <div class="pub-authors">C. Eiras-Franco, A. Hedstr√∂m, M. H√∂hne</div>
        <div class="pub-meta"><em>AAAI</em>, 2025.</div>
        <div class="btn-group">
          <a class="btn" href="https://ojs.aaai.org/index.php/AAAI/article/view/34935" target="_blank" rel="noopener">Paper</a>
          <a class="btn" href="https://github.com/annahedstroem/eval-project" target="_blank" rel="noopener">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{eiras2025evaluate,
  title = {Evaluate with the Inverse: Efficient Approximation of Latent Explanation Quality Distribution},
  author = {Eiras-Franco, Carlos and Hedstr{\"o}m, Anna and H{\"o}hne, Marina MC},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={39},
  year={2025}
}</pre></details>
        </div>
      </div> -->

      <!-- <div class="pub-item">
        <div class="pub-title">Benchmarking XAI Explanations with Human-Aligned Evaluations</div>
        <div class="pub-authors">R. Kazmierczak, S. Azzolin, E. Berthier, A. Hedstr√∂m, Delhomme, N. Bousquet, G. Frehse, M. Mancini, B. Caramiaux, A. Passerini, G. Franchi</div>
        <div class="pub-meta"><em>Under Review</em>, 2025.</div>
        <div class="btn-group">
          <a class="btn" href="#" aria-disabled="true">Paper</a>
          <a class="btn" href="#" aria-disabled="true">Code</a>
          <details class="bibtex"><summary>BibTeX</summary><pre>@inproceedings{ pasta2024benchmarking,
  title={Benchmarking XAI Explanations with Human-Aligned Evaluations},
  author={Kazmierczak, R{\'e}mi and Azzolin, Steve and Berthier, Elo{\'i}se and Hedstr{\"o}m, Anna and Delhomme and Bousquet, Nicolas and Frehse, Goran and Mancini, Massimiliano and Caramiaux, Baptiste and Passerini, Andrea and Franchi, Gianni},
  booktitle={Under Review},
  year={2025}
}</pre></details>
        </div>
      </div> -->


      <h2>News</h2>
      <p><strong>Sep 2025</strong> ‚Äî Started Postdoctoral Fellow at <a href="https://ai.ethz.ch/" target="_blank" rel="noopener"><u>ETH AI Center</u></a> (Zurich, CH) on AI safety</p>
      <p><strong>Aug 2025</strong> ‚Äî Defended Ph.D. thesis in Interpretable Machine Learning at TU Berlin, with distinction! (Berlin, DE)</p>
      <!--<p><strong>Aug 2025</strong> ‚Äî Finished Ph.D. thesis "Evalaution-centric advances in neural model interpretability" (Berlin, DE)</p>-->
      <p><strong>May 2025</strong> ‚Äî <a href="https://openreview.net/pdf?id=fUCPq5RvmH" target="_blank" rel="noopener"><u>Paper</u></a> on LLM steering accepted at ICML 2025 (Vancouver, CA)</p>
      <p><strong>Jan 2025</strong> ‚Äî <a href="https://openreview.net/pdf?id=ukLxqA8zXj&noteId=5ceyt8qT4e" target="_blank" rel="noopener"><u>Paper</u></a> on geometric and unified evaluation awarded a <a href="https://openreview.net/forum?id=ukLxqA8zXj&noteId=5ceyt8qT4e" target="_blank" rel="noopener"><u>survey certification</u></a> by TMLR!</p>
      <p><strong>Dec 2024</strong> ‚Äî Paper on adversarial attacks accepted at <a href="https://openreview.net/pdf?id=BpJK5lFzfM" target="_blank" rel="noopener"><u>NeurIPS Workshop Interpretable AI</u></a> (New Orleans, US)</p>
      <p><strong>Sep 2024</strong> ‚Äî Started AI Research Programme at <a href="https://www.jpmorgan.com/CH/en/about-us" target="_blank" rel="noopener"><u>J.P. Morgan</u></a> (London, UK)</p>
      <p><strong>May 2024</strong> ‚Äî Gave a talk on <a href="https://aiforgood.itu.int/event/explainable-ai-in-the-era-of-large-language-models/" target="_blank" rel="noopener"><u>LLM x interpretability</u></a> at the <a href="https://aiforgood.itu.int/event/explainable-ai-in-the-era-of-large-language-models/" target="_blank" rel="noopener"><u>United Nations AI for Good Global Summit</u></a> (Geneva, CH)</p>
      <p><strong>Feb 2024</strong> ‚Äî Gave a keynote <a href="https://invicta.inesctec.pt/" target="_blank" rel="noopener"><u>lectures</u></a> series in XAI AI <a href="https://invicta.inesctec.pt/" target="_blank" rel="noopener"><u>Invicta School of Artificial Intelligence</u></a> (Porto, PT)</p>
      <p><strong>Feb 2024</strong> ‚Äî Gave a webinar in <a href="https://www.youtube.com/watch?v=cJVgxAOq-4M" target="_blank" rel="noopener"><u>applying XAI in climate science</u></a> at <a href="https://www.climatechange.ai/" target="_blank" rel="noopener"><u>Climate Change AI</u></a> (Virtual)</p>
      <p><strong>Dec 2023</strong> ‚Äî Presented <a href="https://www.jmlr.org/papers/v24/22-0142.html" target="_blank" rel="noopener"><u>Quantus</u></a> in NeurIPS poster sessions (New Orleans, US)</p>
      <p><strong>Dec 2023</strong> ‚Äî Presented <a href="https://github.com/annahedstroem/sanity-checks-revisited" target="_blank" rel="noopener"><u>eMPRT & sMPRT</u></a> at <a href="https://xai-in-action.github.io/" target="_blank" rel="noopener"><u>NeurIPS XAI workshop</u></a> (New Orleans, US)</p>
      <p><strong>Jun 2023</strong> ‚Äî Started visiting scientist at <a href="https://www.hhi.fraunhofer.de/en/departments/ai.html" target="_blank" rel="noopener"><u>Fraunhofer AI Department</u></a> (Berlin, DE)</p>
      <p><strong>Sep 2023</strong> ‚Äî Gave a talk at <a href="https://www.visual-intelligence.no/" target="_blank" rel="noopener"><u>at SFI Visual Intelligence</u></a> (Virtual)</p>
      <p><strong>May 2023</strong> ‚Äî Gave a spotlight tutorial at <a href="https://www.climatechange.ai/papers/iclr2023/1" target="_blank" rel="noopener"><u>ICLR Climate Change AI</u></a> (Kigali, RW)</p>
      <p><strong>Apr 2023</strong> ‚Äî Gave a talk at <a href="https://www.ptb.de/cms/en.html" target="_blank" rel="noopener"><u>Physikalisch-Technische Bundesanstalt (PTB)</u></a> (Berlin, DE)</p>
      <p><strong>Mar 2023</strong> ‚Äî Gave a lecture at <a href="https://www.sfb1294.de/events/event/spring-school-2023" target="_blank" rel="noopener"><u> SFB 1294 Spring School on Data Assimilation</u></a> (Virtual)</p>
      <p><strong>Jan 2023</strong> ‚Äî Gave a tutorial at <a href="https://www.nldl.org/home" target="_blank" rel="noopener"><u>NLDL Deep Learning Conference</u></a>winter school (Troms√∏, NO)</p>

      <!--<p><strong>2022</strong> ‚Äî Gave a talk at<a href="https://www.youtube.com/watch?v=68IPFQjc5FE" target="_blank" rel="noopener"><u>SFI Visual Intelligence</u></a> (Virtual)</p>
      <p><strong>2022</strong> ‚Äî Gave a workshop at<a href="https://www.birs.ca/events/2022/5-day-workshops/22w5055" target="_blank" rel="noopener"><u>Banff International Research Station</u></a> (Banff, CA)</p>
      <p><strong>2022</strong> ‚Äî Gave a <a href="https://engineering.nyu.edu/research-innovation/centers/center-responsible-ai" target="_blank" rel="noopener"><u>talk on Unverifiability in XAI at NYU Tandon School of Engineering</u></a> (New York, US)</p>
      <p><strong>2022</strong> ‚Äî Gave a <a href="https://sites.google.com/view/ssdatascience2022/home" target="_blank" rel="noopener"><u>hands-on session on XAI at 7th Int'l Summer School on Data Science</u></a> (Virtual)</p>
      <p><strong>2021</strong> ‚Äî Gave a <a href="https://www2.deloitte.com/de/de.html" target="_blank" rel="noopener"><u>talk on A sneak-peak to Explainable AI at Deloitte AI Talks</u></a> (Berlin, DE)</p>-->
    </div>
  </main>

  <footer class="site-footer">
    <div class="container">
      ¬© <span id="year"></span> Anna Hedstr√∂m
    </div>
  </footer>
  <script>document.getElementById('year').textContent=new Date().getFullYear()</script>
</body>
</html>
